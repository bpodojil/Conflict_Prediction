{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore 'Future Warnings'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import Necessary Packages\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "import os\n",
    "import random as rn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Psudeorandom Seed\n",
    "seed = 42\n",
    "\n",
    "\n",
    "#os.environ['PYTHONHASHSEED']=str(seed)\n",
    "#np.random.seed(seed)\n",
    "#set_random_seed(seed)\n",
    "#rn.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "files = []\n",
    "\n",
    "files.append(('One Year Alt','../data/1a_offset.xlsx'))\n",
    "#files.append(('Two Year Alt','../data/2a_offset.xlsx'))\n",
    "#files.append(('Three Year Alt','../data/3a_offset.xlsx'))\n",
    "#files.append(('Five Year Alt','../data/5a_offset.xlsx'))\n",
    "#files.append(('Ten Year Alt','../data/10a_offset.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_an = pd.DataFrame(['Algorithm'])\n",
    "df_a_rn = pd.DataFrame(['Algorithm'])\n",
    "df_a_fn = pd.DataFrame(['Algorithm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Brandon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "1230/1230 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|████████▎                                                                          | 1/10 [00:01<00:14,  1.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.93      0.93       914\n",
      "         1.0       0.81      0.81      0.81       316\n",
      "\n",
      "    accuracy                           0.90      1230\n",
      "   macro avg       0.87      0.87      0.87      1230\n",
      "weighted avg       0.90      0.90      0.90      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 31us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|████████████████▌                                                                  | 2/10 [00:06<00:20,  2.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.94      0.93       914\n",
      "         1.0       0.82      0.79      0.81       316\n",
      "\n",
      "    accuracy                           0.90      1230\n",
      "   macro avg       0.87      0.87      0.87      1230\n",
      "weighted avg       0.90      0.90      0.90      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 48us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|████████████████████████▉                                                          | 3/10 [00:08<00:17,  2.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94       914\n",
      "         1.0       0.81      0.82      0.82       316\n",
      "\n",
      "    accuracy                           0.91      1230\n",
      "   macro avg       0.88      0.88      0.88      1230\n",
      "weighted avg       0.91      0.91      0.91      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 72us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:10<00:14,  2.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.94      0.94       914\n",
      "         1.0       0.82      0.80      0.81       316\n",
      "\n",
      "    accuracy                           0.90      1230\n",
      "   macro avg       0.88      0.87      0.87      1230\n",
      "weighted avg       0.90      0.90      0.90      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 70us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:14<00:13,  2.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.94      0.94       914\n",
      "         1.0       0.83      0.81      0.82       316\n",
      "\n",
      "    accuracy                           0.91      1230\n",
      "   macro avg       0.88      0.88      0.88      1230\n",
      "weighted avg       0.91      0.91      0.91      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 79us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:20<00:14,  3.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.92      0.93       914\n",
      "         1.0       0.79      0.81      0.80       316\n",
      "\n",
      "    accuracy                           0.90      1230\n",
      "   macro avg       0.86      0.87      0.86      1230\n",
      "weighted avg       0.90      0.90      0.90      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 94us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:22<00:09,  3.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94       914\n",
      "         1.0       0.82      0.83      0.82       316\n",
      "\n",
      "    accuracy                           0.91      1230\n",
      "   macro avg       0.88      0.88      0.88      1230\n",
      "weighted avg       0.91      0.91      0.91      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 104us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [00:26<00:07,  3.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.93      0.93       914\n",
      "         1.0       0.81      0.81      0.81       316\n",
      "\n",
      "    accuracy                           0.90      1230\n",
      "   macro avg       0.87      0.87      0.87      1230\n",
      "weighted avg       0.90      0.90      0.90      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 114us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [00:34<00:04,  4.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.94      0.93       914\n",
      "         1.0       0.81      0.79      0.80       316\n",
      "\n",
      "    accuracy                           0.90      1230\n",
      "   macro avg       0.87      0.86      0.87      1230\n",
      "weighted avg       0.90      0.90      0.90      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 142us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:36<00:00,  3.69s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:39<00:00, 39.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.94      0.94       914\n",
      "         1.0       0.82      0.81      0.82       316\n",
      "\n",
      "    accuracy                           0.91      1230\n",
      "   macro avg       0.88      0.87      0.88      1230\n",
      "weighted avg       0.91      0.91      0.91      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, file in tqdm(files):\n",
    "    algo_a_mean = []\n",
    "    algo_a_std = []\n",
    "    algo_r_mean = []\n",
    "    algo_r_std = []\n",
    "    algo_f_mean = []\n",
    "    algo_f_std = []\n",
    "    accuracy = np.array([])\n",
    "    recall = np.array([])\n",
    "    f1 = np.array([])\n",
    "\n",
    "    df=pd.read_excel(file)\n",
    "\n",
    "    array = df.values\n",
    "\n",
    "    #Create X array\n",
    "    X= array[:,5:]\n",
    "\n",
    "    # Standardizing the features\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    #Create Y array\n",
    "    Y= array[:,4]\n",
    "    Y=Y.astype('int')\n",
    "\n",
    "    \n",
    "    for i in tqdm(range(10)):\n",
    "\n",
    "        \n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=seed )\n",
    "\n",
    "        sm = SMOTE()\n",
    "        X_train, Y_train = sm.fit_sample(X_train, Y_train)\n",
    "        Y_train=keras.utils.to_categorical(Y_train)\n",
    "        Y_test=keras.utils.to_categorical(Y_test)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(20, activation='relu', input_shape=(41,)))\n",
    "        model.add(Dense(20, activation='relu'))\n",
    "        model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "\n",
    "        history=model.fit(X_train,Y_train, validation_split=0.2, epochs=30,callbacks=[callback], verbose=0)\n",
    "\n",
    "        y_pred = model.predict(X_test, batch_size=64, verbose=1)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        Y_test=Y_test[:,1]\n",
    "\n",
    "\n",
    "        print(classification_report(Y_test, y_pred))\n",
    "\n",
    "        acc = accuracy_score(Y_test, y_pred)\n",
    "        rec = recall_score(Y_test, y_pred)\n",
    "        f=  f1_score(Y_test, y_pred)\n",
    "        accuracy = np.append(accuracy, acc)\n",
    "        recall = np.append(recall, rec)\n",
    "        f1 = np.append(f1, f)\n",
    "    a_mean = accuracy.mean().tolist()\n",
    "    a_std = accuracy.std().tolist()\n",
    "    r_mean = recall.mean().tolist()\n",
    "    r_std = accuracy.std().tolist()\n",
    "    f_mean = f1.mean().tolist()\n",
    "    f_std = accuracy.std().tolist()\n",
    "    algo_a_mean.append(a_mean)\n",
    "    algo_a_std.append(a_std)\n",
    "    algo_r_mean.append(r_mean)\n",
    "    algo_r_std.append(r_std)\n",
    "    algo_f_mean.append(f_mean)\n",
    "    algo_f_std.append(f_std)\n",
    "    df_a_an[name+' mean'] = algo_a_mean\n",
    "    df_a_an[name+' std'] = algo_a_std\n",
    "    df_a_rn[name+' mean'] = algo_r_mean\n",
    "    df_a_rn[name+' std'] = algo_r_std\n",
    "    df_a_fn[name+' mean'] = algo_f_mean\n",
    "    df_a_fn[name+' std'] = algo_f_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>One Year Alt mean</th>\n",
       "      <th>One Year Alt std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Algorithm</td>\n",
       "      <td>0.809177</td>\n",
       "      <td>0.004045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  One Year Alt mean  One Year Alt std\n",
       "0  Algorithm           0.809177          0.004045"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a_rn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Specification w/ PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ap_an = pd.DataFrame(['Algorithm'])\n",
    "df_ap_rn = pd.DataFrame(['Algorithm'])\n",
    "df_ap_fn = pd.DataFrame(['Algorithm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1230/1230 [==============================] - 0s 166us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94       914\n",
      "         1.0       0.82      0.82      0.82       316\n",
      "\n",
      "    accuracy                           0.91      1230\n",
      "   macro avg       0.88      0.88      0.88      1230\n",
      "weighted avg       0.91      0.91      0.91      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 154us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94       914\n",
      "         1.0       0.83      0.82      0.82       316\n",
      "\n",
      "    accuracy                           0.91      1230\n",
      "   macro avg       0.88      0.88      0.88      1230\n",
      "weighted avg       0.91      0.91      0.91      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 191us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94       914\n",
      "         1.0       0.83      0.83      0.83       316\n",
      "\n",
      "    accuracy                           0.91      1230\n",
      "   macro avg       0.89      0.88      0.88      1230\n",
      "weighted avg       0.91      0.91      0.91      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 182us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.94      0.94       914\n",
      "         1.0       0.83      0.81      0.82       316\n",
      "\n",
      "    accuracy                           0.91      1230\n",
      "   macro avg       0.88      0.88      0.88      1230\n",
      "weighted avg       0.91      0.91      0.91      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 212us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.93      0.94       914\n",
      "         1.0       0.81      0.83      0.82       316\n",
      "\n",
      "    accuracy                           0.91      1230\n",
      "   macro avg       0.88      0.88      0.88      1230\n",
      "weighted avg       0.91      0.91      0.91      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 203us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.94      0.94       914\n",
      "         1.0       0.83      0.81      0.82       316\n",
      "\n",
      "    accuracy                           0.91      1230\n",
      "   macro avg       0.88      0.87      0.88      1230\n",
      "weighted avg       0.91      0.91      0.91      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 217us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.93      0.93       914\n",
      "         1.0       0.81      0.81      0.81       316\n",
      "\n",
      "    accuracy                           0.90      1230\n",
      "   macro avg       0.87      0.87      0.87      1230\n",
      "weighted avg       0.90      0.90      0.90      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 228us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94       914\n",
      "         1.0       0.82      0.81      0.82       316\n",
      "\n",
      "    accuracy                           0.91      1230\n",
      "   macro avg       0.88      0.88      0.88      1230\n",
      "weighted avg       0.91      0.91      0.91      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 251us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.95      0.94       914\n",
      "         1.0       0.84      0.80      0.82       316\n",
      "\n",
      "    accuracy                           0.91      1230\n",
      "   macro avg       0.89      0.88      0.88      1230\n",
      "weighted avg       0.91      0.91      0.91      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 251us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:40<00:00, 40.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94       914\n",
      "         1.0       0.83      0.82      0.82       316\n",
      "\n",
      "    accuracy                           0.91      1230\n",
      "   macro avg       0.88      0.88      0.88      1230\n",
      "weighted avg       0.91      0.91      0.91      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, file in tqdm(files):\n",
    "    algo_a_mean = []\n",
    "    algo_a_std = []\n",
    "    algo_r_mean = []\n",
    "    algo_r_std = []\n",
    "    algo_f_mean = []\n",
    "    algo_f_std = []\n",
    "    accuracy = np.array([])\n",
    "    recall = np.array([])\n",
    "    f1 = np.array([])\n",
    "\n",
    "    df=pd.read_excel(file)\n",
    "\n",
    "    \n",
    "    for i in range(10):\n",
    "\n",
    "        array = df.values\n",
    "\n",
    "        #Create X array\n",
    "        X= array[:,5:]\n",
    "\n",
    "        # Standardizing the features\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "\n",
    "        #Create Y array\n",
    "        Y= array[:,4]\n",
    "        Y=Y.astype('int')\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=seed )\n",
    "\n",
    "        sm = SMOTE()\n",
    "        X_train, Y_train = sm.fit_sample(X_train, Y_train)\n",
    "        \n",
    "\n",
    "        pca = PCA(n_components = 20)\n",
    "        principalComponents = pca.fit_transform(X_train)\n",
    "        #print('Using '+pca.n_components_+' PCA variables.')\n",
    "\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "        \n",
    "        Y_train=keras.utils.to_categorical(Y_train)\n",
    "        Y_test=keras.utils.to_categorical(Y_test)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(20, activation='relu', input_shape=(20,)))\n",
    "        model.add(Dense(20, activation='relu'))\n",
    "        model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "\n",
    "        history=model.fit(X_train,Y_train, validation_split=0.2, epochs=30,callbacks=[callback], verbose=0)\n",
    "\n",
    "        y_pred = model.predict(X_test, batch_size=64, verbose=1)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        Y_test=Y_test[:,1]\n",
    "\n",
    "\n",
    "        print(classification_report(Y_test, y_pred))\n",
    "\n",
    "        acc = accuracy_score(Y_test, y_pred)\n",
    "        rec = recall_score(Y_test, y_pred)\n",
    "        f=  f1_score(Y_test, y_pred)\n",
    "        accuracy = np.append(accuracy, acc)\n",
    "        recall = np.append(recall, rec)\n",
    "        f1 = np.append(f1, f)\n",
    "    a_mean = accuracy.mean().tolist()\n",
    "    a_std = accuracy.std().tolist()\n",
    "    r_mean = recall.mean().tolist()\n",
    "    r_std = accuracy.std().tolist()\n",
    "    f_mean = f1.mean().tolist()\n",
    "    f_std = accuracy.std().tolist()\n",
    "    algo_a_mean.append(a_mean)\n",
    "    algo_a_std.append(a_std)\n",
    "    algo_r_mean.append(r_mean)\n",
    "    algo_r_std.append(r_std)\n",
    "    algo_f_mean.append(f_mean)\n",
    "    algo_f_std.append(f_std)\n",
    "    df_ap_an[name+' mean'] = algo_a_mean\n",
    "    df_ap_an[name+' std'] = algo_a_std\n",
    "    df_ap_rn[name+' mean'] = algo_r_mean\n",
    "    df_ap_rn[name+' std'] = algo_r_std\n",
    "    df_ap_fn[name+' mean'] = algo_f_mean\n",
    "    df_ap_fn[name+' std'] = algo_f_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Specification w/ Y/R/C dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ad_an = pd.DataFrame(['Algorithm'])\n",
    "df_ad_rn = pd.DataFrame(['Algorithm'])\n",
    "df_ad_fn = pd.DataFrame(['Algorithm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1230/1230 [==============================] - 0s 327us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 1/10 [00:06<00:57,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.95      0.94       914\n",
      "         1.0       0.84      0.78      0.81       316\n",
      "\n",
      "    accuracy                           0.91      1230\n",
      "   macro avg       0.88      0.87      0.87      1230\n",
      "weighted avg       0.90      0.91      0.91      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 291us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 2/10 [00:15<00:57,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.96      0.95       914\n",
      "         1.0       0.89      0.79      0.83       316\n",
      "\n",
      "    accuracy                           0.92      1230\n",
      "   macro avg       0.91      0.88      0.89      1230\n",
      "weighted avg       0.92      0.92      0.92      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 342us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 3/10 [00:24<00:53,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.95      0.94       914\n",
      "         1.0       0.84      0.81      0.83       316\n",
      "\n",
      "    accuracy                           0.91      1230\n",
      "   macro avg       0.89      0.88      0.88      1230\n",
      "weighted avg       0.91      0.91      0.91      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 332us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:32<00:47,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.96      0.95       914\n",
      "         1.0       0.86      0.81      0.84       316\n",
      "\n",
      "    accuracy                           0.92      1230\n",
      "   macro avg       0.90      0.88      0.89      1230\n",
      "weighted avg       0.92      0.92      0.92      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 332us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:39<00:38,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.96      0.94       914\n",
      "         1.0       0.87      0.78      0.82       316\n",
      "\n",
      "    accuracy                           0.91      1230\n",
      "   macro avg       0.90      0.87      0.88      1230\n",
      "weighted avg       0.91      0.91      0.91      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 345us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:48<00:31,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.96      0.95       914\n",
      "         1.0       0.86      0.81      0.83       316\n",
      "\n",
      "    accuracy                           0.92      1230\n",
      "   macro avg       0.90      0.88      0.89      1230\n",
      "weighted avg       0.92      0.92      0.92      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 393us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:55<00:23,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.94      0.93       914\n",
      "         1.0       0.82      0.77      0.79       316\n",
      "\n",
      "    accuracy                           0.90      1230\n",
      "   macro avg       0.87      0.86      0.86      1230\n",
      "weighted avg       0.90      0.90      0.90      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 364us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [01:06<00:17,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.96      0.94       914\n",
      "         1.0       0.86      0.80      0.83       316\n",
      "\n",
      "    accuracy                           0.92      1230\n",
      "   macro avg       0.90      0.88      0.89      1230\n",
      "weighted avg       0.91      0.92      0.91      1230\n",
      "\n",
      "1230/1230 [==============================] - 0s 389us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:16<00:09,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.94       914\n",
      "         1.0       0.86      0.81      0.83       316\n",
      "\n",
      "    accuracy                           0.92      1230\n",
      "   macro avg       0.90      0.88      0.89      1230\n",
      "weighted avg       0.92      0.92      0.92      1230\n",
      "\n",
      "1230/1230 [==============================] - 1s 419us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:24<00:00,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.96      0.94       914\n",
      "         1.0       0.87      0.78      0.82       316\n",
      "\n",
      "    accuracy                           0.91      1230\n",
      "   macro avg       0.90      0.87      0.88      1230\n",
      "weighted avg       0.91      0.91      0.91      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, file in files:\n",
    "    algo_a_mean = []\n",
    "    algo_a_std = []\n",
    "    algo_r_mean = []\n",
    "    algo_r_std = []\n",
    "    algo_f_mean = []\n",
    "    algo_f_std = []\n",
    "    accuracy = np.array([])\n",
    "    recall = np.array([])\n",
    "    f1 = np.array([])\n",
    "\n",
    "    df=pd.read_excel(file)\n",
    "    #Creation of Year/Region/Country Dummies\n",
    "    year_dummies = pd.get_dummies(df.year, prefix='year').iloc[:,1:]\n",
    "    region_dummies = pd.get_dummies(df.region, prefix='region').iloc[:,1:]\n",
    "    country_dummies = pd.get_dummies(df.ccode, prefix='country: ').iloc[:,1:]\n",
    "    \n",
    "    df = pd.concat([df, year_dummies, region_dummies, country_dummies], axis = 1)\n",
    "    \n",
    "    array = df.values\n",
    "\n",
    "    #Create X array\n",
    "    X= array[:,5:]\n",
    "\n",
    "    # Standardizing the features\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    #Create Y array\n",
    "    Y= array[:,4]\n",
    "    Y=Y.astype('int')\n",
    "\n",
    "    \n",
    "    for i in tqdm(range(10)):\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=seed )\n",
    "\n",
    "        sm = SMOTE()\n",
    "        X_train, Y_train = sm.fit_sample(X_train, Y_train)\n",
    "        Y_train=keras.utils.to_categorical(Y_train)\n",
    "        Y_test=keras.utils.to_categorical(Y_test)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(100, activation='relu', input_shape=(290,)))\n",
    "        model.add(Dense(100, activation='relu'))\n",
    "        model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "\n",
    "        history=model.fit(X_train,Y_train, validation_split=0.2, epochs=30,callbacks=[callback], verbose=0)\n",
    "\n",
    "        y_pred = model.predict(X_test, batch_size=64, verbose=1)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        Y_test=Y_test[:,1]\n",
    "\n",
    "\n",
    "        print(classification_report(Y_test, y_pred))\n",
    "\n",
    "        acc = accuracy_score(Y_test, y_pred)\n",
    "        rec = recall_score(Y_test, y_pred)\n",
    "        f=  f1_score(Y_test, y_pred)\n",
    "        accuracy = np.append(accuracy, acc)\n",
    "        recall = np.append(recall, rec)\n",
    "        f1 = np.append(f1, f)\n",
    "    a_mean = accuracy.mean().tolist()\n",
    "    a_std = accuracy.std().tolist()\n",
    "    r_mean = recall.mean().tolist()\n",
    "    r_std = accuracy.std().tolist()\n",
    "    f_mean = f1.mean().tolist()\n",
    "    f_std = accuracy.std().tolist()\n",
    "    algo_a_mean.append(a_mean)\n",
    "    algo_a_std.append(a_std)\n",
    "    algo_r_mean.append(r_mean)\n",
    "    algo_r_std.append(r_std)\n",
    "    algo_f_mean.append(f_mean)\n",
    "    algo_f_std.append(f_std)\n",
    "    df_ad_an[name+' mean'] = algo_a_mean\n",
    "    df_ad_an[name+' std'] = algo_a_std\n",
    "    df_ad_rn[name+' mean'] = algo_r_mean\n",
    "    df_ad_rn[name+' std'] = algo_r_std\n",
    "    df_ad_fn[name+' mean'] = algo_f_mean\n",
    "    df_ad_fn[name+' std'] = algo_f_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>One Year Alt mean</th>\n",
       "      <th>One Year Alt std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Algorithm</td>\n",
       "      <td>0.793671</td>\n",
       "      <td>0.00635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  One Year Alt mean  One Year Alt std\n",
       "0  Algorithm           0.793671           0.00635"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ad_rn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Specification w/ Y/R/C dummies and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apd_an = pd.DataFrame(columns = ['Algorithm'])\n",
    "df_apd_rn = pd.DataFrame(columns = ['Algorithm'])\n",
    "df_apd_fn = pd.DataFrame(columns = ['Algorithm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1230/1230 [==============================] - 0s 389us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 1/10 [00:06<00:56,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.93      0.94       914\n",
      "         1.0       0.82      0.86      0.84       316\n",
      "\n",
      "    accuracy                           0.91      1230\n",
      "   macro avg       0.88      0.90      0.89      1230\n",
      "weighted avg       0.92      0.91      0.92      1230\n",
      "\n",
      "1230/1230 [==============================] - 1s 421us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 2/10 [00:12<00:50,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.96      0.95       914\n",
      "         1.0       0.86      0.81      0.83       316\n",
      "\n",
      "    accuracy                           0.92      1230\n",
      "   macro avg       0.90      0.88      0.89      1230\n",
      "weighted avg       0.92      0.92      0.92      1230\n",
      "\n",
      "1230/1230 [==============================] - 1s 432us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 3/10 [00:21<00:48,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.93      0.94       914\n",
      "         1.0       0.82      0.86      0.84       316\n",
      "\n",
      "    accuracy                           0.92      1230\n",
      "   macro avg       0.89      0.90      0.89      1230\n",
      "weighted avg       0.92      0.92      0.92      1230\n",
      "\n",
      "1230/1230 [==============================] - 1s 462us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:27<00:41,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.94       914\n",
      "         1.0       0.84      0.82      0.83       316\n",
      "\n",
      "    accuracy                           0.91      1230\n",
      "   macro avg       0.89      0.88      0.89      1230\n",
      "weighted avg       0.91      0.91      0.91      1230\n",
      "\n",
      "1230/1230 [==============================] - 1s 472us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:34<00:34,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.94      0.95       914\n",
      "         1.0       0.84      0.85      0.85       316\n",
      "\n",
      "    accuracy                           0.92      1230\n",
      "   macro avg       0.89      0.90      0.90      1230\n",
      "weighted avg       0.92      0.92      0.92      1230\n",
      "\n",
      "1230/1230 [==============================] - 1s 454us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:40<00:26,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94       914\n",
      "         1.0       0.84      0.83      0.83       316\n",
      "\n",
      "    accuracy                           0.92      1230\n",
      "   macro avg       0.89      0.89      0.89      1230\n",
      "weighted avg       0.92      0.92      0.92      1230\n",
      "\n",
      "1230/1230 [==============================] - 1s 483us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:49<00:21,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.94       914\n",
      "         1.0       0.84      0.82      0.83       316\n",
      "\n",
      "    accuracy                           0.91      1230\n",
      "   macro avg       0.89      0.88      0.89      1230\n",
      "weighted avg       0.91      0.91      0.91      1230\n",
      "\n",
      "1230/1230 [==============================] - 1s 504us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [00:56<00:14,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.94      0.94       914\n",
      "         1.0       0.83      0.85      0.84       316\n",
      "\n",
      "    accuracy                           0.92      1230\n",
      "   macro avg       0.89      0.89      0.89      1230\n",
      "weighted avg       0.92      0.92      0.92      1230\n",
      "\n",
      "1230/1230 [==============================] - 1s 517us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:04<00:07,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.94      0.95       914\n",
      "         1.0       0.83      0.87      0.85       316\n",
      "\n",
      "    accuracy                           0.92      1230\n",
      "   macro avg       0.89      0.90      0.90      1230\n",
      "weighted avg       0.92      0.92      0.92      1230\n",
      "\n",
      "1230/1230 [==============================] - 1s 538us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:17<00:00,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94       914\n",
      "         1.0       0.83      0.82      0.82       316\n",
      "\n",
      "    accuracy                           0.91      1230\n",
      "   macro avg       0.88      0.88      0.88      1230\n",
      "weighted avg       0.91      0.91      0.91      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, file in files:\n",
    "    algo_a_mean = []\n",
    "    algo_a_std = []\n",
    "    algo_r_mean = []\n",
    "    algo_r_std = []\n",
    "    algo_f_mean = []\n",
    "    algo_f_std = []\n",
    "    accuracy = np.array([])\n",
    "    recall = np.array([])\n",
    "    f1 = np.array([])\n",
    "\n",
    "    df=pd.read_excel(file)\n",
    "    #Creation of Year/Region/Country Dummies\n",
    "    year_dummies = pd.get_dummies(df.year, prefix='year').iloc[:,1:]\n",
    "    region_dummies = pd.get_dummies(df.region, prefix='region').iloc[:,1:]\n",
    "    country_dummies = pd.get_dummies(df.ccode, prefix='country: ').iloc[:,1:]\n",
    "    \n",
    "    df = pd.concat([df, year_dummies, region_dummies, country_dummies], axis = 1)\n",
    "    \n",
    "    for i in tqdm(range(10)):\n",
    "\n",
    "        array = df.values\n",
    "\n",
    "        #Create X array\n",
    "        X= array[:,5:]\n",
    "\n",
    "        # Standardizing the features\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "\n",
    "        #Create Y array\n",
    "        Y= array[:,4]\n",
    "        Y=Y.astype('int')\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=seed )\n",
    "\n",
    "        sm = SMOTE()\n",
    "        X_train, Y_train = sm.fit_sample(X_train, Y_train)\n",
    "\n",
    "        pca = PCA(n_components=100)\n",
    "        principalComponents = pca.fit_transform(X_train)\n",
    "        #print('Using '+pca.n_components_+' PCA variables.')\n",
    "\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "        \n",
    "        Y_train=keras.utils.to_categorical(Y_train)\n",
    "        Y_test=keras.utils.to_categorical(Y_test)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(20, activation='relu', input_shape=(100,)))\n",
    "        model.add(Dense(20, activation='relu'))\n",
    "        model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "\n",
    "        history=model.fit(X_train,Y_train, validation_split=0.2, epochs=30,callbacks=[callback], verbose=0)\n",
    "\n",
    "        y_pred = model.predict(X_test, batch_size=64, verbose=1)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        Y_test=Y_test[:,1]\n",
    "\n",
    "\n",
    "        print(classification_report(Y_test, y_pred))\n",
    "\n",
    "        acc = accuracy_score(Y_test, y_pred)\n",
    "        rec = recall_score(Y_test, y_pred)\n",
    "        f=  f1_score(Y_test, y_pred)\n",
    "        accuracy = np.append(accuracy, acc)\n",
    "        recall = np.append(recall, rec)\n",
    "        f1 = np.append(f1, f)\n",
    "    a_mean = accuracy.mean().tolist()\n",
    "    a_std = accuracy.std().tolist()\n",
    "    r_mean = recall.mean().tolist()\n",
    "    r_std = accuracy.std().tolist()\n",
    "    f_mean = f1.mean().tolist()\n",
    "    f_std = accuracy.std().tolist()\n",
    "    algo_a_mean.append(a_mean)\n",
    "    algo_a_std.append(a_std)\n",
    "    algo_r_mean.append(r_mean)\n",
    "    algo_r_std.append(r_std)\n",
    "    algo_f_mean.append(f_mean)\n",
    "    algo_f_std.append(f_std)\n",
    "    df_apd_an[name+' mean'] = algo_a_mean\n",
    "    df_apd_an[name+' std'] = algo_a_std\n",
    "    df_apd_rn[name+' mean'] = algo_r_mean\n",
    "    df_apd_rn[name+' std'] = algo_r_std\n",
    "    df_apd_fn[name+' mean'] = algo_f_mean\n",
    "    df_apd_fn[name+' std'] = algo_f_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to excel file\n",
    "\n",
    "df_a_an.to_excel('../data/a_an.xlsx')\n",
    "df_a_rn.to_excel('../data/a_rn.xlsx')\n",
    "df_a_fn.to_excel('../data/a_fn.xlsx')\n",
    "\n",
    "df_ap_an.to_excel('../data/ap_an.xlsx')\n",
    "df_ap_rn.to_excel('../data/ap_rn.xlsx')\n",
    "df_ap_fn.to_excel('../data/ap_fn.xlsx')\n",
    "\n",
    "df_ad_an.to_excel('../data/ad_an.xlsx')\n",
    "df_ad_rn.to_excel('../data/ad_rn.xlsx')\n",
    "df_ad_fn.to_excel('../data/ad_fn.xlsx')\n",
    "\n",
    "df_apd_an.to_excel('../data/apd_an.xlsx')\n",
    "df_apd_rn.to_excel('../data/apd_rn.xlsx')\n",
    "df_apd_fn.to_excel('../data/apd_fn.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
